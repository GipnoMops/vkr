{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9415aa-1ec5-46f3-97d6-e14094cb71c3",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f99af11-2c8d-406f-9346-0f147812e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, sum, when, count, max\n",
    "from dump import spark\n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.sql import HiveContext, types\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json \n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1156f-a955-4fc1-be71-eda383a1fe3e",
   "metadata": {},
   "source": [
    "# assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30484769-8a6f-4c1a-a059-c10c790158a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = pd.read_csv('/usr/home/ymmorozov/urls/assets.csv')\n",
    "necessary_columns = ['ts','dt','asset_id','ad_id','asset_type','asset_role_name', 'url', 'content']\n",
    "mask = assets['asset_role_name'].isin(['title', 'description', 'click_url'])\n",
    "assets = assets[mask][necessary_columns].sort_values(by=['ad_id'])\n",
    "#assets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42be0d3d-60a9-480b-bb59-cd3ff350825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597 1155 1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-7f39cb0583b2>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  assets = assets[mask][necessary_columns].sort_values(by=['ts'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1143"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets = assets[mask][necessary_columns].sort_values(by=['ts'])\n",
    "\n",
    "a1 = assets[assets['asset_role_name'] == 'click_url'].groupby('ad_id').tail(1).ad_id.unique()\n",
    "a2 = assets[assets['asset_role_name'] == 'description'].groupby('ad_id').tail(1).ad_id.unique()\n",
    "a3 = assets[assets['asset_role_name'] == 'title'].groupby('ad_id').tail(1).ad_id.unique()\n",
    "\n",
    "print( len(a1),  len(a2),  len(a3))\n",
    "len(set(a1) & set(a2) & set(a3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "123e4d05-649f-44f6-8d01-7d60b676bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = assets[assets['asset_role_name'] == 'click_url'].groupby('ad_id').tail(1)[['ad_id', 'ts', 'url']]\n",
    "a1 = a1.rename(columns={\"ts\": \"click_url_ts\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c46099b-efe0-49c2-8a00-68eb4eae5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = assets[assets['asset_role_name'] == 'description'].groupby('ad_id').tail(1)[['ad_id', 'ts', 'content']]\n",
    "a2 = a2.rename(columns={\"ts\": \"description_ts\", 'content' : 'description_content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4c871f-e69c-4c53-9599-87f318f2c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = assets[assets['asset_role_name'] == 'title'].groupby('ad_id').tail(1)[['ad_id', 'ts', 'content']]\n",
    "a3 = a3.rename(columns={\"ts\": \"title_ts\", 'content': 'title_content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b711c-8784-4e56-8f1e-9f71b7a8b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = a1.join(a2.set_index('ad_id'), on='ad_id').join(a3.set_index('ad_id'), on='ad_id')\n",
    "#joined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b3b6c2-8098-4edb-8876-31df9c2ac74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1597,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.ad_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0605d7-0807-46e1-a8ca-8360553d3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.to_csv('ad_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5f508-210f-4a1d-b1a1-881832ae18bc",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb35cfe-4019-4cc7-839e-e9ce8a00fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark.context.stop()\n",
    "    spark_task.stop_context()\n",
    "    spark_task = None\n",
    "except (AttributeError, NameError):\n",
    "    pass\n",
    "\n",
    "\n",
    "spark_config = {\n",
    "    'spark.speculation': 'True',\n",
    "    'spark.sql.shuffle.partitions': '512',\n",
    "    'spark.driver.extraJavaOptions': '-XX:MaxPermSize=384m',\n",
    "    'spark.executor.extraJavaOptions': '-XX:MaxPermSize=384m',\n",
    "    'spark.locality.wait': '3',\n",
    "    'spark.locality.wait.process': '3',\n",
    "    'spark.locality.wait.node': '3',\n",
    "    'spark.locality.wait.rack': '3',\n",
    "    'spark.master': 'yarn',\n",
    "    'spark.sql.parquet.compression.codec': 'gzip',\n",
    "    'spark.jars': ######\n",
    "    'spark.yarn.queue': 'HungerGames',\n",
    "    'spark.app.name': 'experiments',\n",
    "    'spark.driver.memory': '8g',\n",
    "    'spark.executor.memory': '24g',\n",
    "    'spark.executor.cores': '4',\n",
    "    'spark.executor.instances': '35',\n",
    "    'spark.driver.maxResultSize': '20g',\n",
    "    'spark.sql.execution.arrow.pyspark.enabled': 'true',\n",
    "    'spark.sql.execution.arrow.pyspark.fallback.enabled': 'true',\n",
    "    'hive.exec.dynamic.partition.mode': 'nonstrict',\n",
    "    'hive.exec.dynamic.partition': 'true',\n",
    "}\n",
    "\n",
    "sc = spark.context.start(spark_config)\n",
    "sqlContext = HiveContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784daab0-5636-44dd-9b0c-5a04b0bb60dc",
   "metadata": {},
   "source": [
    "# join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6ba36a3-f7e2-458a-b460-1d851dcb0b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dt: string, bid_id: string, request_page_url: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests = spark.table(\"ods_pdsp.requests\")\n",
    "requests = requests.select('dt', 'bid_id', 'request_page_url')\n",
    "requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef5055db-bf0a-4e35-92f1-84f74663f81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dt: string, bid_id: string, ad_id: int, campaign_id: int, impression_flg: boolean, click_flg: boolean]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = spark.table(\"ods_pdsp.events\")\n",
    "events = events.select('dt', 'bid_id', 'ad_id', 'campaign_id', 'impression_flg', 'click_flg')\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17a094bc-7315-457b-8546-7a91315d2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_df = pd.read_csv('ad_df.csv')\n",
    "\n",
    "values_list = ad_df['ad_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90be3ed3-481d-4757-ba2f-db01633e4b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-31 13:57:33'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_df['click_url_ts'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84238c5b-2116-44de-b7ee-2f341773191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 2024-04-23\n"
     ]
    }
   ],
   "source": [
    "min_dt = str(datetime.strptime( ad_df['click_url_ts'].min(), \"%Y-%m-%d %H:%M:%S\").date() )\n",
    "max_dt = str(datetime.strptime( ad_df['click_url_ts'].max(), \"%Y-%m-%d %H:%M:%S\").date() )\n",
    "print(min_dt, max_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679907e8-2548-4701-9075-af774d67f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = events.filter((col(\"dt\") >= min_dt) & (col(\"dt\") <= max_dt) & col(\"ad_id\").isin(values_list)).drop('dt')\n",
    "re = requests.filter((col(\"dt\") >= min_dt) & (col(\"dt\") <= max_dt)).drop('dt')\n",
    "\n",
    "re.join(ev, on='bid_id').groupBy(['campaign_id', \"ad_id\", 'request_page_url']).agg(\n",
    "    sum(when(col(\"click_flg\") == True, 1).otherwise(0)).alias(\"clicks_count\"),\n",
    "    sum(when(col(\"impression_flg\") == True, 1).otherwise(0)).alias(\"impression_count\")\n",
    ").write.saveAsTable(\"ymmorozov_clicks_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6adb9f-64dc-429a-9330-4644531f6aee",
   "metadata": {},
   "source": [
    "# sizes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe870609-738c-48d4-b7f2-0ce6b413e900",
   "metadata": {},
   "source": [
    "spark.table(\"ymmorozov_clicks_data\").count()\n",
    ">>> 38829300\n",
    "\n",
    "spark.table(\"ymmorozov_clicks_data\").filter(col(\"impression_count\") > 0).count()\n",
    ">>> 2557832\n",
    "\n",
    "spark.table(\"ymmorozov_clicks_data\").filter(col(\"clicks_count\") > 0).count()\n",
    ">>> 11778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ace56f-eeac-482d-b2cf-a9858b4aeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impres_100 = spark.table(\"ymmorozov_clicks_data\").filter(col(\"impression_count\") > 100).toPandas().sort_values(by='clicks_count')\n",
    "df_impres_100['ctr'] = df_impres_100['clicks_count'] / df_impres_100['impression_count']\n",
    "df_impres_100 = df_impres_100.sort_values(by='ctr')\n",
    "\n",
    "#df_impres_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b690f-f66f-473e-bb8f-00bdb4392c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_pars1 = df_impres_100['request_page_url'].unique().tolist()\n",
    "\n",
    "with open('urls_to_pars1.pkl', 'wb') as f:\n",
    "    pickle.dump(urls_to_pars1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed286a-ab43-44f6-badb-bb44ac8ea9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_to_pars_id = df_impres_100['ad_id'].unique().tolist()\n",
    "\n",
    "ad_df = pd.read_csv('ad_df.csv')\n",
    "ad_to_pars = ad_df[ad_df['ad_id'].isin(ad_to_pars_id)][['ad_id', 'url']]\n",
    "\n",
    "ad_to_pars.to_csv('ad_to_pars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11ef48-8638-4689-97de-2ea21fabd63d",
   "metadata": {},
   "source": [
    "# html по url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf1708-5244-4865-86a0-d1c5e825ab41",
   "metadata": {},
   "source": [
    "собирал тексты с сайтов вот таким кодом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302eb7c-5713-462b-841a-51cf14fc55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def fetch_html(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return True, response.text \n",
    "    except requests.RequestException as e:\n",
    "        return False, None \n",
    "\n",
    "count_true = 0\n",
    "htmls = {}\n",
    "errors = []\n",
    "\n",
    "for url in tqdm.tqdm(urls_to_pars1):\n",
    "    boo, resp = fetch_html(url)\n",
    "    if not boo:\n",
    "        errors.append(url)\n",
    "    else:\n",
    "        count_true += 1\n",
    "        htmls[url] = resp\n",
    "\n",
    "print('true  count:\\t', count_true)\n",
    "print('erros count:\\t', len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4df2a-03b5-4de3-a12f-4f743b765861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html реклам\n",
    "with open(\"htmls1.json\", \"w\") as f:\n",
    "    json.dump(htmls, f)\n",
    "    \n",
    "# html сайтов \n",
    "with open(\"ad_htmls.json\", \"w\") as f:\n",
    "    json.dump(htmls, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcbdf05-8cd1-4cf5-b7dc-744653cf4623",
   "metadata": {},
   "source": [
    "# парсинг текста из html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578314f6-c538-4fb0-afa2-80d4a8cfb031",
   "metadata": {},
   "source": [
    "постобрабатывал текста таким кодом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e96f48-1ba6-42bf-b896-f4704ef83054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"htmls1.json\", \"r\") as f:\n",
    "    htmls1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80d204-11e3-45ae-b0d0-8e56cb718fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pars_html(html):\n",
    "    try:      \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        re_  = re.sub('\\n+', '\\n', re.sub(' +', ' ', soup.get_text()))\n",
    "        \n",
    "        return True, re_\n",
    "    except:\n",
    "        return False, None \n",
    "\n",
    "\n",
    "count_true = 0\n",
    "parsed_htmls = {}\n",
    "errors_id = []\n",
    "\n",
    "for url in tqdm.tqdm(htmls1.keys()):\n",
    "    try:\n",
    "        boo, pars = pars_html(htmls1[url])\n",
    "        if boo:\n",
    "            parsed_htmls[url] = pars\n",
    "            count_true += 1\n",
    "        if not boo:\n",
    "            errors_id.append(url)\n",
    "    except:\n",
    "        errors_id.append(url)\n",
    "\n",
    "print(count_true)\n",
    "print(errors_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63029a53-e8bb-4eea-a599-22e9d94e096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# текста реклам\n",
    "with open(\"ad_parsed.json\", \"w\") as f:\n",
    "    json.dump(parsed_htmls, f)\n",
    "\n",
    "# текста сайтов\n",
    "with open(\"urls_parsed.json\", \"w\") as f:\n",
    "    json.dump(parsed_htmls, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99208d83-4e95-4bc1-b6a8-01cdb81549df",
   "metadata": {},
   "source": [
    "# fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234540ec-c99b-463b-83b8-4fbe505af6cd",
   "metadata": {},
   "source": [
    "fasttext векторизует каждое слово в тексте и суммирует полученные вектора (нужно было попробовать mean, что-то забыл про это)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4740ad-8dfa-4729-a1a2-dcb9c5032cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def fasttext_encode(df, model, column_to_encode):\n",
    "    \n",
    "    def f(text):\n",
    "        separate_words = re.findall(r'\\b[\\w-]+\\b', text)\n",
    "        encodes = model[separate_words]\n",
    "        return encodes.sum(axis=0).tolist() \n",
    "\n",
    "    encode_udf = udf(f, ArrayType(FloatType()))\n",
    "    #encode_udf(df['parsed_html'])\n",
    "    df = df.withColumn('vector', encode_udf(df[column_to_encode]))\n",
    "    df = df.drop(column_to_encode)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45860f14-0607-4925-b915-a806e10ae9ed",
   "metadata": {},
   "source": [
    "# BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82e3f5-5055-4c40-8957-7d439beb54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# саму модельку грузим\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0067ca-4182-4117-a4ff-d8b5f10fefdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faafe37c-e32d-4b70-aa17-01b888c1faec",
   "metadata": {},
   "source": [
    "У этой модельки ограничение на длинну контекста 512 токенов. Рассматривал 4 способа векторизации: \n",
    "* embed_bert_cls - подаём модель 512 первых букв и берём CLS токен\n",
    "* embed_bert_cls2 - подаём модель 512 первых токенов и берём CLS токен\n",
    "* embed_bert_cls3 - режим текст на куски 512 токенов, получаем их CLS и берём сумму \n",
    "* embed_bert_cls4 - режим текст на куски 512 токенов, получаем их CLS и берём mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e2a48-0f80-467e-a9d3-906b77fcbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    temp_text = text[:512]\n",
    "    t = tokenizer(temp_text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd9cf7-3dac-48bb-a760-69d187839b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls2(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v[:, :512].to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "print(embed_bert_cls('привет мир! Как житуха, как дела?', model, tokenizer).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f10940-3939-40aa-b804-b351c67a2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls3(text, model, tokenizer, max_length=512):\n",
    "    tokens = tokenizer(text, padding=False, truncation=False, return_tensors='pt')\n",
    "    input_ids = tokens['input_ids'][0]\n",
    "    attention_mask = tokens['attention_mask'][0]\n",
    "    \n",
    "    num_chunks = (len(input_ids) + max_length - 1) // max_length  # вычисляем количество частей\n",
    "    \n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_chunks):\n",
    "            chunk_input_ids = input_ids[i * max_length: (i + 1) * max_length].unsqueeze(0).to(model.device)\n",
    "            chunk_attention_mask = attention_mask[i * max_length: (i + 1) * max_length].unsqueeze(0).to(model.device)\n",
    "            \n",
    "            model_output = model(input_ids=chunk_input_ids, attention_mask=chunk_attention_mask)\n",
    "            chunk_embedding = model_output.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(chunk_embedding)\n",
    "    \n",
    "    # Суммируем все полученные CLS токены и нормализуем\n",
    "    total_embedding = torch.sum(torch.stack(embeddings), dim=0)\n",
    "    total_embedding = torch.nn.functional.normalize(total_embedding)\n",
    "    \n",
    "    return total_embedding[0].cpu().numpy()\n",
    "\n",
    "# Пример использования\n",
    "text = \"Твой текст здесь\"\n",
    "embedding = embed_bert_cls3(text, model, tokenizer)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe877aca-ae67-4be3-94b7-3b00a5707f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls4(text, model, tokenizer, max_length=512):\n",
    "    tokens = tokenizer(text, padding=False, truncation=False, return_tensors='pt')\n",
    "    input_ids = tokens['input_ids'][0]\n",
    "    attention_mask = tokens['attention_mask'][0]\n",
    "    \n",
    "    num_chunks = (len(input_ids) + max_length - 1) // max_length  # вычисляем количество частей\n",
    "    \n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_chunks):\n",
    "            chunk_input_ids = input_ids[i * max_length: (i + 1) * max_length].unsqueeze(0).to(model.device)\n",
    "            chunk_attention_mask = attention_mask[i * max_length: (i + 1) * max_length].unsqueeze(0).to(model.device)\n",
    "            \n",
    "            model_output = model(input_ids=chunk_input_ids, attention_mask=chunk_attention_mask)\n",
    "            chunk_embedding = model_output.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(chunk_embedding)\n",
    "    \n",
    "    # Суммируем все полученные CLS токены и нормализуем\n",
    "    total_embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "    total_embedding = torch.nn.functional.normalize(total_embedding)\n",
    "    \n",
    "    return total_embedding[0].cpu().numpy()\n",
    "\n",
    "# Пример использования\n",
    "text = \"Твой текст здесь Твой текст здесь Твой текст здесь\"\n",
    "embedding = embed_bert_cls4(text, model, tokenizer)\n",
    "print(embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221d4b4-aa12-4fc3-b985-211861a06eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6015ee-66f6-4b5d-b59e-43a6aa477086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b21cdfa-52cd-44e2-ac18-c0954b1cfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "st_to_encode = 'site_text' # имя столбца по которому будет строиться эмбединг сайта \n",
    "ad_to_encode = 'ad_text'   # имя столбца по которому будет строиться эмбединг рекламы\n",
    "st_encodes = 'site_vec'    # имя столбца в котором будет храниться вектор сайта\n",
    "ad_encodes = 'ad_vec'      # имя столбца в котором будет храниться вектор рекламы\n",
    "metric_name = 'cos_sim'    # имя метрики метрики\n",
    "\n",
    "f = embed_bert_cls4        # функция которая будет выдавать эмбединги \n",
    "\n",
    "df[st_encodes] = None\n",
    "df.loc[df[st_to_encode].notna(), st_encodes] = df[df[st_to_encode].notna()][st_to_encode].progress_apply(lambda x: np.array(f(x, model, tokenizer)))\n",
    "\n",
    "\n",
    "df[ad_encodes] = None\n",
    "df.loc[df[ad_to_encode].notna(), ad_encodes] = df[df[ad_to_encode].notna()][ad_to_encode].progress_apply(lambda x: np.array(f(x, model, tokenizer)))\n",
    "\n",
    "\n",
    "df[metric_name] = None\n",
    "df.loc[df[st_encodes].notna() & df[ad_encodes].notna(), metric_name] = df[df[st_encodes].notna() & df[ad_encodes].notna()][[st_encodes, ad_encodes]].apply(lambda x: cos_sim([x[0]], [x[1]])[0][0], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398421c-44d4-4bee-bceb-7b8e293304e2",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c198f-b8f1-4e47-9e14-a3135466b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_text_to_encode_column_name   = 'ad_og_content'\n",
    "site_text_to_encode_column_name = 'site_og_content'\n",
    "\n",
    "ad_encode_column_name   = 'ad_tf_idf_og'\n",
    "site_encode_column_name = 'site_tf_idf_og'\n",
    "\n",
    "\n",
    "\n",
    "site_dict = ddf[['site_id', site_text_to_encode_column_name]].drop_duplicates().set_index('site_id')[site_text_to_encode_column_name].to_dict()\n",
    "ad_dict = ddf[['ad_id', ad_text_to_encode_column_name]].drop_duplicates().set_index('ad_id')[ad_text_to_encode_column_name].to_dict()\n",
    "\n",
    "corpus = list(site_dict.values()) + list(ad_dict.values())\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False, norm=None)\n",
    "idf_matrix = vectorizer.fit_transform(corpus)\n",
    "idf_values = vectorizer.idf_\n",
    "\n",
    "list_idf_vec = [i for i in idf_matrix]\n",
    "\n",
    "site_list_len = len(list(site_dict.values()))\n",
    "ad_list_len   = len(list(ad_dict.values()))\n",
    "\n",
    "site_vec = list_idf_vec[:site_list_len]\n",
    "ad_vec   = list_idf_vec[site_list_len:]\n",
    "\n",
    "site_id_vec_dict = {key: value for key, value in zip(site_dict.keys(), site_vec)}\n",
    "ad_id_vec_dict   = {key: value for key, value in zip(ad_dict.keys(), ad_vec)}\n",
    "\n",
    "\n",
    "\n",
    "ddf[ad_encode_column_name] = None\n",
    "ddf[site_encode_column_name] = None\n",
    "\n",
    "ddf[ad_encode_column_name] = ddf.ad_id.apply(lambda x: ad_id_vec_dict[x])\n",
    "ddf[site_encode_column_name] = ddf.site_id.apply(lambda x: site_id_vec_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7642bbda-1d83-472e-85b8-d632fb6dfc54",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad7f338-4f0a-419d-b05b-b11b3a37008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/usr/home/ymmorozov/urls/data_select/new_metrics.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d236261-7cff-4275-af2e-b338f3a75a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df[df.cos_sim3.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fdea129-0742-4d50-bdeb-942d5d1b956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5252636875500968 0.002783120198903399\n"
     ]
    }
   ],
   "source": [
    "scores_col_name = 'cos_sim3' # имя колонки явл являющаяся оценкой моделью релевантности рекламы сайту \n",
    "\n",
    "\n",
    "ddf = ddf[['ad_id', 'site_id', \"impression_count\", 'clicks_count', scores_col_name]]\n",
    "\n",
    "ddf['click_flg'] = ddf.apply(lambda x: [1] * int(x[3]) + [0] * int(x[2] - x[3]), axis=1)\n",
    "ddf = ddf.explode('click_flg')\n",
    "\n",
    "\n",
    "\n",
    "y_true = ddf.click_flg.tolist()\n",
    "y_scores = ddf[scores_col_name].tolist()\n",
    "\n",
    "auc_roc = roc_auc_score(y_true, y_scores)\n",
    "auc_pr = average_precision_score(y_true, y_scores)\n",
    "\n",
    "print(auc_roc, auc_pr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ebceb-d2d4-428f-8714-3101d6534b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525757ab-cbcd-4889-b940-86c0e3a89c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "97b6aef7-f03f-4353-8806-2646fccd5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df, scores_col_name, true_col_name=None):\n",
    "    ddf = df[df[scores_col_name].notna()]\n",
    "    \n",
    "    if true_col_name is None: \n",
    "        ddf = ddf[['ad_id', 'site_id', \"impression_count\", 'clicks_count', scores_col_name]]\n",
    "        ddf['click_flg'] = ddf.apply(lambda x: [1] * int(x[3]) + [0] * int(x[2] - x[3]), axis=1)\n",
    "        ddf = ddf.explode('click_flg')\n",
    "        true_col_name = 'click_flg'\n",
    "    else: \n",
    "        ddf = ddf[ddf[true_col_name].notna()]\n",
    "        ddf = ddf[['ad_id', 'site_id', true_col_name, scores_col_name]]\n",
    "\n",
    "    \n",
    "    def auc_count(temp_df, temp_scores, temp_true): \n",
    "        y_true = temp_df[temp_true].tolist()\n",
    "        y_scores = temp_df[temp_scores].tolist()\n",
    "        auc_roc = roc_auc_score(y_true, y_scores)\n",
    "        auc_pr = average_precision_score(y_true, y_scores)\n",
    "        return auc_roc, auc_pr \n",
    "\n",
    "    ddf['true_order'] = list(range(ddf.shape[0]))\n",
    "    ddf['reverse_order'] = list(range(ddf.shape[0]))[::-1]\n",
    "    ordinary_auc_roc, ordinary_auc_pr = auc_count(ddf, scores_col_name, true_col_name)\n",
    "    max_auc_roc, max_auc_pr = auc_count(ddf, 'true_order', true_col_name)\n",
    "    min_auc_roc, min_auc_pr = auc_count(ddf, 'reverse_order', true_col_name)\n",
    "    \n",
    "    roc_border = (min_auc_roc + (1 - max_auc_roc)) / 2\n",
    "    normalized_auc_roc = (ordinary_auc_roc - roc_border) / (1 - 2 * roc_border)\n",
    "\n",
    "    res = {\n",
    "        'auc_roc' : {\n",
    "            'ordinary' : ordinary_auc_roc,\n",
    "            'max' : max_auc_roc,\n",
    "            'min' : min_auc_roc,\n",
    "            'normalized' : normalized_auc_roc,\n",
    "        },\n",
    "        'auc_pr' : {\n",
    "            'ordinary' : ordinary_auc_pr,\n",
    "            'max' : max_auc_pr,\n",
    "            'min' : min_auc_pr,\n",
    "        },\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09ac75ae-e3c2-465f-9215-77d7b745ee51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_roc': {'ordinary': 0.5252636875500968,\n",
       "  'max': 0.7896248996726905,\n",
       "  'min': 0.21037510032730955,\n",
       "  'normalized': 0.5436144951256741},\n",
       " 'auc_pr': {'ordinary': 0.002783120198903399,\n",
       "  'max': 0.009733642307554781,\n",
       "  'min': 0.0014592577487050986}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = df[df.cos_sim3.notna()]\n",
    "evaluate(ddf, 'cos_sim3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62956d1f-320a-4074-8bc9-99bdc259eb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f0df8-5673-455e-ac15-2332c679a5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa76cd-bb86-4554-b032-04591d0f2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def evaluate_by_groups(df, scores_col_name, true_col_name=None):\n",
    "    \n",
    "    ddf = df[df[scores_col_name].notna()]\n",
    "    \n",
    "    if true_col_name is None: \n",
    "        ddf = ddf[['ad_id', 'site_id', \"impression_count\", 'clicks_count', scores_col_name]]\n",
    "        ddf['click_flg'] = ddf.apply(lambda x: [1] * int(x[3]) + [0] * int(x[2] - x[3]), axis=1)\n",
    "        ddf = ddf.explode('click_flg')\n",
    "        true_col_name = 'click_flg'\n",
    "    else: \n",
    "        ddf = ddf[ddf[true_col_name].notna()]\n",
    "        ddf = ddf[['ad_id', 'site_id', true_col_name, scores_col_name]]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def subgroup_auc(temp_df, temp_scores, temp_true):\n",
    "        if temp_df[temp_true].sum() == 0 or temp_df.shape[0] == 0:\n",
    "            return None\n",
    "        metrict = evaluate(temp_df, temp_scores, temp_true)\n",
    "        return pd.Series({'impression_count' : len(y_true),\n",
    "                          'ord_auc_roc': metrict['auc_roc']['ordinary'],\n",
    "                          'max_auc_roc': metrict['auc_roc']['max'],\n",
    "                          'min_auc_roc': metrict['auc_roc']['min'],\n",
    "                          'norm_auc_roc': metrict['auc_roc']['normalized'],\n",
    "\n",
    "                          'ord_auc_pr': metrict['auc_pr']['ordinary'],\n",
    "                          'max_auc_pr': metrict['auc_pr']['max'],\n",
    "                          'min_auc_pr': metrict['auc_pr']['min'],\n",
    "                            })  \n",
    "    \n",
    "    \n",
    "    result = ddf.groupby('ad_id').apply(lambda x: subgroup_auc(x, scores_col_name, true_col_name) ).reset_index()\n",
    "    return result\n",
    "    \n",
    "res = evaluate_by_groups(df, 'cos_sim3')\n",
    "res\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
